{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BilalTalha/Car-game/blob/master/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPgrZuklG-Pg",
        "colab_type": "code",
        "outputId": "827685e9-7cec-46ca-f0bc-ab803eba9cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.33.6)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (41.4.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (0.16.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a9tbyFqHaaY",
        "colab_type": "code",
        "outputId": "a0c43512-4802-4ef4-bc7e-28b7b5967324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip3 install imageai --upgrade"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imageai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/99/4023e191a343fb23f01ae02ac57a5ca58037c310e8d8c62f87638a3bafc7/imageai-2.1.5-py3-none-any.whl (180kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from imageai) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imageai) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from imageai) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->imageai) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.4.2)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageai) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imageai) (41.4.0)\n",
            "Installing collected packages: imageai\n",
            "Successfully installed imageai-2.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxxi16cMHfyb",
        "colab_type": "code",
        "outputId": "5a9afbda-ad07-4706-ccf8-2ff21854b110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-05 15:59:10--  https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/125932201/12701d80-b2ab-11e9-9f56-c06e1dfbec05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191105T155911Z&X-Amz-Expires=300&X-Amz-Signature=eef016ea2199f465cdc6912a0560336e6edad561bd8a65f53e722ec44dc35e25&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dpretrained-yolov3.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-11-05 15:59:11--  https://github-production-release-asset-2e65be.s3.amazonaws.com/125932201/12701d80-b2ab-11e9-9f56-c06e1dfbec05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191105T155911Z&X-Amz-Expires=300&X-Amz-Signature=eef016ea2199f465cdc6912a0560336e6edad561bd8a65f53e722ec44dc35e25&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dpretrained-yolov3.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.137.220\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.137.220|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248671664 (237M) [application/octet-stream]\n",
            "Saving to: ‘pretrained-yolov3.h5’\n",
            "\n",
            "pretrained-yolov3.h 100%[===================>] 237.15M  69.6MB/s    in 3.4s    \n",
            "\n",
            "2019-11-05 15:59:14 (69.6 MB/s) - ‘pretrained-yolov3.h5’ saved [248671664/248671664]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyw4k-B8Hmbg",
        "colab_type": "code",
        "outputId": "eb049151-3390-497f-937c-d5ad194da8fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!wget https://github.com/BilalTalha/Car-game/raw/master/Braintumor.zip"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-05 15:59:20--  https://github.com/BilalTalha/Car-game/raw/master/Braintumor.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BilalTalha/Car-game/master/Braintumor.zip [following]\n",
            "--2019-11-05 15:59:20--  https://raw.githubusercontent.com/BilalTalha/Car-game/master/Braintumor.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7877614 (7.5M) [application/zip]\n",
            "Saving to: ‘Braintumor.zip’\n",
            "\n",
            "Braintumor.zip      100%[===================>]   7.51M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-11-05 15:59:21 (62.9 MB/s) - ‘Braintumor.zip’ saved [7877614/7877614]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWnrnxYFHwVG",
        "colab_type": "code",
        "outputId": "84a2bc6c-8583-401e-b81a-46dfd192520e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip Braintumor.zip"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Braintumor.zip\n",
            "   creating: Braintumor/train/\n",
            "   creating: Braintumor/train/annotations/\n",
            "  inflating: Braintumor/train/annotations/1.0---97374-i658.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97374-i659.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97374-i660.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97374-i661.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97374-i662.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97607-i174.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97607-i175.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97607-i176.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97607-i177.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97607-i178.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97607-i665.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97607-i666.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97737-i179.xml  \n",
            "  inflating: Braintumor/train/annotations/1.0---97737-i180.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i791.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i792.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i793.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i794.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i795.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i796.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i797.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i864.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i865.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---88670-i866.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---90284-i801.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---90284-i802.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---90284-i803.xml  \n",
            "  inflating: Braintumor/train/annotations/2.0---90284-i804.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97416-i1579.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97416-i1765.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97416-i1766.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97416-i1767.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97416-i1768.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97416-i1769.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97416-i1770.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97416-i1771.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97461-i1580.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97461-i1581.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97461-i1587.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97461-i1772.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97461-i1773.xml  \n",
            "  inflating: Braintumor/train/annotations/3.0---97461-i1774.xml  \n",
            "   creating: Braintumor/train/images/\n",
            "  inflating: Braintumor/train/images/1.0---97374-i658.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97374-i659.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97374-i660.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97374-i661.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97374-i662.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97607-i174.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97607-i175.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97607-i176.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97607-i177.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97607-i178.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97607-i665.jpg  \n",
            "  inflating: Braintumor/train/images/1.0---97607-i666.bmp  \n",
            "  inflating: Braintumor/train/images/1.0---97737-i179.jpg  \n",
            "  inflating: Braintumor/train/images/1.0---97737-i180.jpg  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i791.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i792.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i793.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i794.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i795.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i796.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i797.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i864.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i865.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---88670-i866.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---90284-i801.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---90284-i802.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---90284-i803.bmp  \n",
            "  inflating: Braintumor/train/images/2.0---90284-i804.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97416-i1579.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97416-i1765.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97416-i1766.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97416-i1767.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97416-i1768.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97416-i1769.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97416-i1770.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97416-i1771.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97461-i1580.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97461-i1581.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97461-i1587.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97461-i1772.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97461-i1773.bmp  \n",
            "  inflating: Braintumor/train/images/3.0---97461-i1774.bmp  \n",
            "   creating: Braintumor/validation/\n",
            "   creating: Braintumor/validation/annotations/\n",
            "  inflating: Braintumor/validation/annotations/1.0---97737-i181.xml  \n",
            "  inflating: Braintumor/validation/annotations/1.0---97737-i182.xml  \n",
            "  inflating: Braintumor/validation/annotations/1.0---97737-i407.xml  \n",
            "  inflating: Braintumor/validation/annotations/1.0---97737-i408.xml  \n",
            "  inflating: Braintumor/validation/annotations/1.0---97737-i409.xml  \n",
            "  inflating: Braintumor/validation/annotations/1.0---97737-i410.xml  \n",
            "  inflating: Braintumor/validation/annotations/2.0---90284-i805.xml  \n",
            "  inflating: Braintumor/validation/annotations/2.0---90284-i869.xml  \n",
            "  inflating: Braintumor/validation/annotations/2.0---90284-i870.xml  \n",
            "  inflating: Braintumor/validation/annotations/2.0---90284-i871.xml  \n",
            "  inflating: Braintumor/validation/annotations/2.0---90284-i872.xml  \n",
            "  inflating: Braintumor/validation/annotations/2.0---90284-i873.xml  \n",
            "  inflating: Braintumor/validation/annotations/3.0---97461-i1775.xml  \n",
            "  inflating: Braintumor/validation/annotations/3.0---97461-i1776.xml  \n",
            "  inflating: Braintumor/validation/annotations/3.0---97461-i1777.xml  \n",
            "  inflating: Braintumor/validation/annotations/3.0---97461-i1778.xml  \n",
            "  inflating: Braintumor/validation/annotations/3.0---97461-i1779.xml  \n",
            "  inflating: Braintumor/validation/annotations/3.0---97481-i1588.xml  \n",
            "   creating: Braintumor/validation/images/\n",
            "  inflating: Braintumor/validation/images/1.0---97737-i181.bmp  \n",
            "  inflating: Braintumor/validation/images/1.0---97737-i182.bmp  \n",
            "  inflating: Braintumor/validation/images/1.0---97737-i407.bmp  \n",
            "  inflating: Braintumor/validation/images/1.0---97737-i408.bmp  \n",
            "  inflating: Braintumor/validation/images/1.0---97737-i409.jpg  \n",
            "  inflating: Braintumor/validation/images/1.0---97737-i410.jpg  \n",
            "  inflating: Braintumor/validation/images/2.0---90284-i805.bmp  \n",
            "  inflating: Braintumor/validation/images/2.0---90284-i869.bmp  \n",
            "  inflating: Braintumor/validation/images/2.0---90284-i870.bmp  \n",
            "  inflating: Braintumor/validation/images/2.0---90284-i871.bmp  \n",
            "  inflating: Braintumor/validation/images/2.0---90284-i872.bmp  \n",
            "  inflating: Braintumor/validation/images/2.0---90284-i873.bmp  \n",
            "  inflating: Braintumor/validation/images/3.0---97461-i1775.bmp  \n",
            "  inflating: Braintumor/validation/images/3.0---97461-i1776.bmp  \n",
            "  inflating: Braintumor/validation/images/3.0---97461-i1777.bmp  \n",
            "  inflating: Braintumor/validation/images/3.0---97461-i1778.bmp  \n",
            "  inflating: Braintumor/validation/images/3.0---97461-i1779.bmp  \n",
            "  inflating: Braintumor/validation/images/3.0---97481-i1588.bmp  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33kIJuIfIO44",
        "colab_type": "code",
        "outputId": "e98609fd-e05d-4819-9767-86ce44ad7c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"Braintumor\")\n",
        "trainer.setTrainConfig(object_names_array=[\"menigiomia\",\"Gliomia\",\"pituirity\"], batch_size=4, num_experiments=5, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.87\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  Braintumor/json/detection_config.json\n",
            "Training on: \t['Gliomia', 'menigiomia', 'pituirity']\n",
            "Training with Batch Size:  4\n",
            "Number of Experiments:  5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Training with transfer learning from pretrained Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 2929s 33s/step - loss: 74.6059 - yolo_layer_1_loss: 8.9349 - yolo_layer_2_loss: 20.4967 - yolo_layer_3_loss: 45.1743 - val_loss: 38.6317 - val_yolo_layer_1_loss: 5.4496 - val_yolo_layer_2_loss: 11.7481 - val_yolo_layer_3_loss: 21.4340\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 2948s 34s/step - loss: 30.1721 - yolo_layer_1_loss: 4.4765 - yolo_layer_2_loss: 8.9472 - yolo_layer_3_loss: 16.7483 - val_loss: 20.4699 - val_yolo_layer_1_loss: 3.3340 - val_yolo_layer_2_loss: 6.8244 - val_yolo_layer_3_loss: 10.3116\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 2530s 29s/step - loss: 19.1256 - yolo_layer_1_loss: 3.0515 - yolo_layer_2_loss: 6.4510 - yolo_layer_3_loss: 9.6231 - val_loss: 15.0491 - val_yolo_layer_1_loss: 2.5527 - val_yolo_layer_2_loss: 5.4446 - val_yolo_layer_3_loss: 7.0518\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 2558s 29s/step - loss: 16.2098 - yolo_layer_1_loss: 2.6022 - yolo_layer_2_loss: 5.5889 - yolo_layer_3_loss: 8.0186 - val_loss: 11.8014 - val_yolo_layer_1_loss: 2.1184 - val_yolo_layer_2_loss: 4.1814 - val_yolo_layer_3_loss: 5.5016\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 2943s 33s/step - loss: 15.4425 - yolo_layer_1_loss: 2.6606 - yolo_layer_2_loss: 5.2017 - yolo_layer_3_loss: 7.5803 - val_loss: 12.0177 - val_yolo_layer_1_loss: 1.3260 - val_yolo_layer_2_loss: 4.6965 - val_yolo_layer_3_loss: 5.9952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GRm03oVTU1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e34c10fe-2984-47c1-e889-5bf87721b65d"
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"Braintumor\")\n",
        "trainer.evaluateModel(model_path=\"Braintumor/models\", json_path=\"Braintumor/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Model evaluation....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model File:  Braintumor/models/detection_model-ex-001--loss-0074.606.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "Gliomia: 0.0040\n",
            "menigiomia: 0.0000\n",
            "pituirity: 0.0000\n",
            "mAP: 0.0013\n",
            "===============================\n",
            "Model File:  Braintumor/models/detection_model-ex-002--loss-0030.172.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "Gliomia: 0.0933\n",
            "menigiomia: 0.5602\n",
            "pituirity: 0.1875\n",
            "mAP: 0.2803\n",
            "===============================\n",
            "Model File:  Braintumor/models/detection_model-ex-003--loss-0019.126.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "Gliomia: 0.0806\n",
            "menigiomia: 0.9524\n",
            "pituirity: 0.0119\n",
            "mAP: 0.3483\n",
            "===============================\n",
            "Model File:  Braintumor/models/detection_model-ex-004--loss-0016.210.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "Gliomia: 0.0366\n",
            "menigiomia: 0.1225\n",
            "pituirity: 0.1026\n",
            "mAP: 0.0872\n",
            "===============================\n",
            "Model File:  Braintumor/models/detection_model-ex-005--loss-0015.443.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "Gliomia: 0.0889\n",
            "menigiomia: 0.8333\n",
            "pituirity: 0.2292\n",
            "mAP: 0.3838\n",
            "===============================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'average_precision': {'Gliomia': 0.003968253968253968,\n",
              "   'menigiomia': 0.0,\n",
              "   'pituirity': 0.0},\n",
              "  'map': 0.0013227513227513227,\n",
              "  'model_file': 'Braintumor/models/detection_model-ex-001--loss-0074.606.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'Gliomia': 0.0933048433048433,\n",
              "   'menigiomia': 0.5601851851851852,\n",
              "   'pituirity': 0.1875},\n",
              "  'map': 0.2803300094966762,\n",
              "  'model_file': 'Braintumor/models/detection_model-ex-002--loss-0030.172.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'Gliomia': 0.08055555555555555,\n",
              "   'menigiomia': 0.9523809523809523,\n",
              "   'pituirity': 0.011904761904761904},\n",
              "  'map': 0.34828042328042325,\n",
              "  'model_file': 'Braintumor/models/detection_model-ex-003--loss-0019.126.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'Gliomia': 0.036585365853658534,\n",
              "   'menigiomia': 0.12254901960784315,\n",
              "   'pituirity': 0.10256410256410256},\n",
              "  'map': 0.08723282934186809,\n",
              "  'model_file': 'Braintumor/models/detection_model-ex-004--loss-0016.210.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'Gliomia': 0.08888888888888888,\n",
              "   'menigiomia': 0.8333333333333333,\n",
              "   'pituirity': 0.22916666666666666},\n",
              "  'map': 0.38379629629629625,\n",
              "  'model_file': 'Braintumor/models/detection_model-ex-005--loss-0015.443.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-8nVbqTZOsw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0e70b48a-63a8-4a40-e133-7da9fd097109"
      },
      "source": [
        "!wget https://drive.google.com/open?id=1og96Q7dPfe2tNnsIOUlT2Yb85GSaPaWJ"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-05 21:08:20--  https://drive.google.com/open?id=1og96Q7dPfe2tNnsIOUlT2Yb85GSaPaWJ\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.215.100, 173.194.215.139, 173.194.215.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.215.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 OK\n",
            "Location: https://drive.google.com/file/d/1og96Q7dPfe2tNnsIOUlT2Yb85GSaPaWJ/view?usp=drive_open [following]\n",
            "--2019-11-05 21:08:20--  https://drive.google.com/file/d/1og96Q7dPfe2tNnsIOUlT2Yb85GSaPaWJ/view?usp=drive_open\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘open?id=1og96Q7dPfe2tNnsIOUlT2Yb85GSaPaWJ’\n",
            "\n",
            "\r          open?id=1     [<=>                 ]       0  --.-KB/s               \ropen?id=1og96Q7dPfe     [ <=>                ]  66.48K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-11-05 21:08:21 (6.05 MB/s) - ‘open?id=1og96Q7dPfe2tNnsIOUlT2Yb85GSaPaWJ’ saved [68075]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWLZaYHUZfR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be8103d6-f6b8-4682-b24c-a69ffdcc6bbb"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Braintumor\t 'open?id=1og96Q7dPfe2tNnsIOUlT2Yb85GSaPaWJ'   sample_data\n",
            " Braintumor.zip   pretrained-yolov3.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh3qHoklXHfL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "3fad1601-929b-47c0-82e1-e39ab5b26f30"
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(\"Braintumor/models/detection_model-ex-005--loss-0015.443.h5\") \n",
        "detector.setJsonPath(\"Braintumor/json/detection_config.json\")\n",
        "detector.loadModel()\n",
        "detections = detector.detectObjectsFromImage(input_image=\"tumor.bmp\", output_image_path=\"tumor-detected.jpg\")\n",
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-5de8944218ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetJsonPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Braintumor/json/detection_config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectObjectsFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tumor.bmp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_image_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tumor-detected.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"percentage_probability\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"box_points\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/__init__.py\u001b[0m in \u001b[0;36mdetectObjectsFromImage\u001b[0;34m(self, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, nms_treshold, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_type must be 'file' or 'array'. {} found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0mimage_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnBXkSMDPHED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "692b27a2-eda9-4b75-924b-d4e6783da6d4"
      },
      "source": [
        "!ls\n",
        "%cd content\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "[Errno 2] No such file or directory: 'content'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}